{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Image data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 train와 test로 나누어서 실습함 \n",
    "\n",
    "- text+data\n",
    "- text+rdata\n",
    "- data+rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunjin\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\sunjin\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\sunjin\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#64면 32->64로 변경해주어야 함\n",
    "def load_image_files(container_path, dimension=(32,32)):\n",
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\"\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [fo.name for fo in folders]\n",
    "\n",
    "    descr = \"A image classification dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        for file in direc.iterdir():\n",
    "            img = imread(file)\n",
    "            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "            flat_data.append(img_resized.flatten()) \n",
    "            images.append(img_resized)\n",
    "            target.append(i)\n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "    images = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_dataset = load_image_files(\"D://cyberforensic_dataset/data_rdata_train\")\n",
    "image_test_dataset = load_image_files(\"D://cyberforensic_dataset/data_rdata_test\")\n",
    "#text&data, text&rdata, data&rdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train, X_test, y_train, y_test = train_test_split(\\n    image_dataset.data, image_dataset.target, test_size=0.3,random_state=109)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = image_train_dataset.data\n",
    "y_train = image_train_dataset.target\n",
    "X_test = image_test_dataset.data\n",
    "y_test = image_test_dataset.target\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.3,random_state=109)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27107843, 0.04264706, 0.23235294, ..., 0.03088235, 0.00882353,\n",
       "        0.02303922],\n",
       "       [0.61764706, 0.0745098 , 0.57745098, ..., 0.07598039, 0.07107843,\n",
       "        0.05931373],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.37352941, 0.27009804, 0.37303922, ..., 0.10294118, 0.15343137,\n",
       "        0.19460784],\n",
       "       [0.57401961, 0.79558824, 0.57598039, ..., 0.2122549 , 0.16519608,\n",
       "        0.21519608],\n",
       "       [0.44460784, 0.28186275, 0.46029412, ..., 0.21960784, 0.15294118,\n",
       "        0.10931373]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.52058824, 0.08039216, 0.475     , ..., 0.18333333, 0.18431373,\n",
       "        0.14754902],\n",
       "       [0.43529412, 0.28333333, 0.41078431, ..., 0.16813725, 0.24313725,\n",
       "        0.20245098],\n",
       "       [0.40392157, 0.27892157, 0.40686275, ..., 0.03137255, 0.03088235,\n",
       "        0.01862745]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predict_labels = rf.predict(X_test)\n",
    "print(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941156803744567\n",
      "\n",
      "[[ 152  148]\n",
      " [  28 2663]]\n",
      "\n",
      "Precision: 0.9473496976165066\n",
      "\n",
      "Recall: 0.9895949461166852\n",
      "\n",
      "F1: 0.9680116321337696\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test, predict_labels))\n",
    "print(\"\")\n",
    "print(confusion_matrix(y_test, predict_labels))\n",
    "print(\"\")\n",
    "print('Precision:',precision_score(y_test, predict_labels))\n",
    "print(\"\")\n",
    "print('Recall:',recall_score(y_test, predict_labels))\n",
    "print(\"\")\n",
    "print('F1:',f1_score(y_test, predict_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Accuracy 요약]\n",
    "\n",
    "- data :  0.85\n",
    "- rdata: 0.81\n",
    "- reloc: 0.63\n",
    "- rsrc: 0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00050983, 0.0013896 , 0.00068278, ..., 0.00128364, 0.00124075,\n",
       "       0.00046177])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1024):\n",
    "    if rf.feature_importances_[i]== 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 30}\n",
      "최고 예측 정확도: 0.8884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[30, 50, 100, 150, 200, 300],\n",
    "    'max_depth' : [4, 6, 8, 10], \n",
    "    'min_samples_leaf' : [8, 12, 18],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = ensemble.RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
